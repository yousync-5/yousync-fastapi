# RQ (Redis Queue) 도입 작업 계획서

**작업 일자**: 2025년 7월 10일  
**예상 소요 시간**: 4-6시간  
**목표**: 현재 BackgroundTasks 방식을 RQ 작업 큐로 전환

## 🎯 작업 목표

### 현재 상황
- **BackgroundTasks**: FastAPI 프로세스 내에서 백그라운드 처리
- **httpx 직접 통신**: 분석 서버와 직접 HTTP 통신
- **제한적 동시성**: 프로세스 내 처리로 확장성 제한

### 목표 상황
- **RQ 작업 큐**: Redis 기반 진짜 큐 시스템
- **Worker 분리**: 별도 프로세스에서 작업 처리
- **확장 가능**: Worker 여러 개 실행으로 동시 처리

## 📋 작업 단계별 계획

### Phase 1: 환경 설정 (30분)

#### 1.1 Redis 설치 및 실행
```bash
# macOS
brew install redis
brew services start redis

# 연결 테스트
redis-cli ping
# 응답: PONG
```

#### 1.2 Python 패키지 설치
```bash
cd back-end
pip install rq redis rq-dashboard
pip freeze > requirements.txt
```

#### 1.3 환경 변수 추가
```bash
# .env 파일에 추가
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
USE_RQ_QUEUE=true  # RQ 사용 여부 제어
```

### Phase 2: RQ 설정 파일 생성 (30분)

#### 2.1 Redis 클라이언트 설정
```python
# back-end/redis_client.py 생성
import redis
import os
from rq import Queue

# Redis 연결
redis_client = redis.Redis(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=int(os.getenv('REDIS_DB', 0)),
    decode_responses=True
)

# 큐 생성
audio_analysis_queue = Queue('audio_analysis', connection=redis_client)
high_priority_queue = Queue('high_priority', connection=redis_client)

# 연결 테스트 함수
def test_redis_connection():
    try:
        redis_client.ping()
        print("✅ Redis 연결 성공")
        return True
    except Exception as e:
        print(f"❌ Redis 연결 실패: {e}")
        return False
```

#### 2.2 작업 함수 디렉토리 생성
```bash
mkdir back-end/tasks
touch back-end/tasks/__init__.py
```

### Phase 3: 작업 함수 구현 (1-2시간)

#### 3.1 기존 코드 분리
```python
# back-end/tasks/audio_analysis.py 생성
import json
import logging
from typing import Dict, Any
from database import SessionLocal
from models import AnalysisResult

def process_audio_analysis(job_id: str, s3_url: str, token_info: Dict[str, Any]):
    """
    RQ 작업 함수: 기존 process_in_background 로직을 그대로 이동
    """
    # 기존 process_in_background 함수 내용을 여기로 이동
    # 새로운 DB 세션 생성
    # S3 업로드는 이미 완료된 상태
    # 분석 서버 요청 및 웹훅 처리
    pass
```

#### 3.2 헬퍼 함수들 이동
```python
# 기존 user_audio_router.py의 함수들을 tasks 모듈로 이동
- send_analysis_request_async()
- update_analysis_result()
- 기타 헬퍼 함수들
```

### Phase 4: API 엔드포인트 수정 (1-2시간)

#### 4.1 user_audio_router.py 수정
```python
# 기존 BackgroundTasks 방식
background_tasks.add_task(process_in_background, s3_client)

# RQ 방식으로 변경
from redis_client import audio_analysis_queue
from tasks.audio_analysis import process_audio_analysis

# 환경 변수로 방식 선택
if os.getenv('USE_RQ_QUEUE', 'false').lower() == 'true':
    # RQ 방식
    job = audio_analysis_queue.enqueue(
        process_audio_analysis,
        job_id=job_id,
        s3_url=s3_url,
        token_info=token_info_dict,
        job_timeout='15m',
        retry=3
    )
else:
    # 기존 BackgroundTasks 방식 (하위 호환)
    background_tasks.add_task(process_in_background, s3_client)
```

#### 4.2 새로운 API 엔드포인트 추가
```python
# 큐 상태 조회
@router.get("/queue/status")
def get_queue_status():
    return {
        "audio_analysis": {
            "length": len(audio_analysis_queue),
            "failed_count": audio_analysis_queue.failed_job_registry.count
        }
    }

# 작업 취소
@router.delete("/jobs/{job_id}/cancel")
def cancel_job(job_id: str):
    # RQ 작업 취소 로직
    pass
```

### Phase 5: Worker 설정 (30분)

#### 5.1 Worker 실행 스크립트
```python
# back-end/workers/rq_worker.py 생성
import os
import sys
from rq import Worker
from redis_client import redis_client

def run_worker():
    queue_names = ['high_priority', 'audio_analysis']
    worker = Worker(queue_names, connection=redis_client)
    worker.work(with_scheduler=True)

if __name__ == '__main__':
    run_worker()
```

#### 5.2 실행 명령어 스크립트
```bash
# start_worker.sh 생성
#!/bin/bash
cd back-end
python workers/rq_worker.py
```

### Phase 6: 테스트 및 검증 (1-2시간)

#### 6.1 기능 테스트
```python
# 테스트 시나리오
1. 오디오 업로드 → RQ 큐에 작업 추가 확인
2. Worker 실행 → 작업 처리 확인
3. 분석 완료 → 웹훅 수신 확인
4. SSE 스트림 → 실시간 상태 업데이트 확인
```

#### 6.2 성능 테스트
```python
# 동시 요청 테스트
- 여러 오디오 파일 동시 업로드
- 큐에 순서대로 쌓이는지 확인
- Worker가 순차적으로 처리하는지 확인
```

#### 6.3 에러 처리 테스트
```python
# 실패 시나리오 테스트
- Redis 연결 실패
- Worker 프로세스 종료
- 분석 서버 응답 실패
- 재시도 메커니즘 동작 확인
```

## 🔧 실행 방법

### 개발 환경 실행
```bash
# 터미널 1: FastAPI 서버
cd back-end
uvicorn main:app --reload

# 터미널 2: RQ Worker
cd back-end
python workers/rq_worker.py

# 터미널 3: RQ Dashboard (선택사항)
rq-dashboard --redis-url redis://localhost:6379
```

### 프로덕션 배포
```bash
# systemd 서비스 등록 또는 Docker 컨테이너로 실행
# Worker 프로세스 여러 개 실행으로 동시 처리 향상
```

## 📊 예상 개선 효과

### 성능 개선
- **동시 처리**: Worker 수만큼 동시 작업 가능
- **메모리 효율**: 작업이 별도 프로세스에서 실행
- **응답 시간**: 큐 추가 후 즉시 응답 (기존과 동일)

### 안정성 개선
- **재시도**: 자동 3회 재시도
- **타임아웃**: 15분 후 자동 실패 처리
- **모니터링**: RQ Dashboard로 실시간 모니터링

### 확장성 개선
- **수평 확장**: Worker 프로세스 추가로 처리량 증가
- **우선순위**: 긴급 작업 우선 처리 가능
- **배치 처리**: 대량 작업 효율적 처리

## 🚨 주의사항

### 1. 하위 호환성
- 환경 변수 `USE_RQ_QUEUE=false`로 기존 방식 유지 가능
- 문제 발생시 즉시 롤백 가능

### 2. Redis 의존성
- Redis 서버 장애시 큐 시스템 전체 영향
- Redis 메모리 사용량 모니터링 필요

### 3. Worker 프로세스 관리
- Worker 프로세스 자동 재시작 설정 필요
- 프로덕션에서는 systemd 또는 Docker로 관리

## 📅 작업 일정

| 시간 | 작업 내용 | 예상 소요 시간 |
|------|-----------|----------------|
| 09:00-09:30 | 환경 설정 (Redis 설치, 패키지 설치) | 30분 |
| 09:30-10:00 | RQ 설정 파일 생성 | 30분 |
| 10:00-12:00 | 작업 함수 구현 (기존 코드 이동) | 2시간 |
| 13:00-15:00 | API 엔드포인트 수정 | 2시간 |
| 15:00-15:30 | Worker 설정 | 30분 |
| 15:30-17:30 | 테스트 및 검증 | 2시간 |

**총 예상 시간**: 7시간 (여유시간 포함)

## 🎯 성공 기준

- ✅ 기존 기능 모두 정상 동작
- ✅ RQ 큐에 작업이 정상적으로 추가됨
- ✅ Worker가 작업을 순차적으로 처리
- ✅ 실패시 자동 재시도 동작
- ✅ RQ Dashboard에서 모니터링 가능
- ✅ 기존 방식으로 롤백 가능

---

**작업 시작 전 체크리스트**:
- [ ] Redis 설치 및 실행 확인
- [ ] 기존 코드 백업 완료
- [ ] 테스트 환경 준비
- [ ] 롤백 계획 수립

**작업 완료 후 체크리스트**:
- [ ] 모든 기능 테스트 통과
- [ ] 성능 개선 확인
- [ ] 문서 업데이트
- [ ] 팀원 공유 및 교육
