# router/script_audio_router.py
import os, logging, asyncio, json, io, httpx
from uuid import uuid4
from concurrent.futures import ThreadPoolExecutor
from fastapi import (
    APIRouter, Path, UploadFile, File, Request,
    BackgroundTasks, Depends, HTTPException
)
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session, joinedload
from database import get_db, SessionLocal
from models import Script, AnalysisResult
from schemas import ScriptUser, ScriptWordUser      # â˜… Pydantic ìŠ¤í‚¤ë§ˆ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
S3_BUCKET   = os.getenv("S3_BUCKET_NAME")
TARGET_URL  = os.getenv("SCRIPT_TARGET_SERVER_URL")
WEBHOOK_URL = os.getenv("SCRIPT_WEBHOOK_URL")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_script_result(db: Session, job_id: str, token_id: int , user_id: int = None):

    ar = AnalysisResult(
        job_id=job_id, 
        token_id=token_id,
        user_id=user_id,
        # script_id=script_id,
        status="processing", 
        progress=10, 
        message="ì—…ë¡œë“œ ì‹œì‘"
    )

    db.add(ar); 
    db.commit(); 
    db.refresh(ar); 
    return ar

def update_script_result(db: Session, job_id: str, **kw):
    ar = db.query(AnalysisResult).filter_by(job_id=job_id).first()
    if ar:
        for k, v in kw.items(): setattr(ar, k, v)
        db.commit(); db.refresh(ar)
    return ar

def get_script_result(db: Session, job_id: str):
    return db.query(AnalysisResult).filter_by(job_id=job_id).first()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ScriptUser ë¹Œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_script_user(db: Session, script_id: int) -> ScriptUser:
    script: Script = (
        db.query(Script)
          .options(joinedload(Script.words))
          .filter_by(id=script_id).first()
    )
    if not script:
        raise HTTPException(404, "Script not found")

    words = [
        ScriptWordUser(
            id=w.id,
            start_time=w.start_time,
            end_time=w.end_time,
            word=w.word,
            mfcc=w.mfcc        # DBì— ì €ì¥ë¼ ìˆë˜ MFCC(2-D ë¦¬ìŠ¤íŠ¸)
        ) for w in script.words
    ]
    return ScriptUser(id=script.id, words=words)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¹„ë™ê¸° ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def upload_to_s3_async(s3_client, file_bytes: bytes, filename: str) -> str:
    def _sync():
        key = f"audio/{uuid4().hex}_{filename}"
        s3_client.upload_fileobj(io.BytesIO(file_bytes), S3_BUCKET, key)
        return key
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as ex:
        return await loop.run_in_executor(ex, _sync)

async def send_analysis_async(s3_url: str, script_obj: ScriptUser,
                              webhook_url: str, job_id: str):
    """ë¶„ì„ ì„œë²„ë¡œ JSON(payload) ì „ì†¡"""
    payload = {
        "s3_audio_url": s3_url,
        "webhook_url":  webhook_url,
        "script":       script_obj.dict()   # Pydantic â†’ dict
    }
    # JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”
    form_data = {
        "request_data": json.dumps(payload, ensure_ascii=False)
    }

    try:
        async with httpx.AsyncClient(timeout=30) as client:
            resp = await client.post(
                url=TARGET_URL,
                data=form_data,  # â˜… json=X, data=O
                headers={"Content-Type": "application/x-www-form-urlencoded"}
            )
            resp.raise_for_status()
            logging.info(f"[ë¶„ì„ ìš”ì²­ ì„±ê³µ] job_id={job_id}")
    except httpx.HTTPError as e:
        logging.error(f"[ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨] job_id={job_id} - {e}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Router â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/scripts", tags=["scripts"])

# 1) ì—…ë¡œë“œ + ë¶„ì„ ìš”ì²­
@router.post("/{script_id}/upload-audio/")
async def upload_script_audio(
    request: Request,
    script_id: int = Path(...),
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: Session = Depends(get_db),
):
    script = db.query(Script).filter_by(id=script_id).first()

    if not script:
        raise HTTPException(404, "Script not found")

    # ScriptUser ê°ì²´ë¡œ ì§ë ¬í™”
    script_obj = build_script_user(db, script_id)

    # S3Â·ë¶„ì„ ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸
    s3_client   = request.app.state.s3_client
    job_id      = uuid4().hex
    file_bytes  = await file.read()

    create_script_result(db, job_id, token_id=script.token_id)

    async def bg_work(client_):
        bg_db = SessionLocal()
        try:
            update_script_result(bg_db, job_id, progress=40, message="S3 ì—…ë¡œë“œ")
            key   = await upload_to_s3_async(client_, file_bytes, file.filename)
            s3url = f"s3://{S3_BUCKET}/{key}"

            update_script_result(bg_db, job_id, progress=70, message="ë¶„ì„ ì„œë²„ í˜¸ì¶œ")
            cb    = f"{WEBHOOK_URL}?job_id={job_id}"
            await send_analysis_async(s3url, script_obj, cb, job_id)

            # ì›¹í›… ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
            update_script_result(bg_db, job_id, progress=90, message="ë¶„ì„ ì¤‘â€¦")
                
        except Exception as e:
            logging.error(e)
            update_script_result(bg_db, job_id, status="failed",
                                 message=str(e), progress=0)
        finally:
            bg_db.close()

    background_tasks.add_task(bg_work, s3_client)
    return {"message": "ì—…ë¡œë“œ ì™„ë£Œ, ë¶„ì„ ì‹œì‘",
            "job_id": job_id, "status": "processing"}

# 2) ë¶„ì„ ì„œë²„ ì›¹í›…
@router.post("/webhook/analysis-complete/")
async def analysis_webhook(request: Request, db: Session = Depends(get_db)):
    # ì›¹í›… í˜¸ì¶œ ë¡œê¹… ì¶”ê°€
    logging.info("=" * 50)
    logging.info("[ğŸ”” ì›¹í›… í˜¸ì¶œë¨] Scripts ë¶„ì„ ê²°ê³¼ ì›¹í›… ìˆ˜ì‹ ")
    logging.info(f"[ì›¹í›… ìš”ì²­ IP] {request.client.host if request.client else 'Unknown'}")
    logging.info(f"[ì›¹í›… í—¤ë”] {dict(request.headers)}")
    
    job_id = request.query_params.get("job_id")
    logging.info(f"[ì›¹í›… íŒŒë¼ë¯¸í„°] job_id={job_id}")
    
    if not job_id:
        logging.warning("[â—ê²½ê³ ] Scripts ì›¹í›…ì— job_id ì—†ìŒ")
        raise HTTPException(400, "job_id missing")
        
    payload = await request.json()
    logging.info(f"[ì›¹í›… ë°ì´í„°] ë°›ì€ ê²°ê³¼ í¬ê¸°: {len(str(payload))} ë¬¸ì")
    logging.info(f"[ì›¹í›… ë°ì´í„°] ê²°ê³¼ í‚¤ë“¤: {list(payload.keys()) if isinstance(payload, dict) else 'Not dict'}")
    
    update_script_result(db, job_id, status="completed",
                         progress=100, result=payload, message="ë¶„ì„ ì™„ë£Œ")
    
    logging.info(f"[âœ… ì›¹í›… ì²˜ë¦¬ ì™„ë£Œ] job_id={job_id}")
    logging.info("=" * 50)
    return {"received": True, "job_id": job_id}

# 3) ê²°ê³¼ ì¡°íšŒ
@router.get("/analysis-result/{job_id}/")
def get_result(job_id: str, db: Session = Depends(get_db)):
    r = get_script_result(db, job_id)
    if not r:
        raise HTTPException(404, "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return {
        "job_id":    r.job_id,
        "token_id":  r.token_id,   # script_id í•„ë“œ ì œê±°
        # "script_id": r.script_id,
        "status":    r.status,
        "progress":  r.progress,
        "result":    r.result,
        "message":   r.message,
        "created_at": r.created_at,
    }

# 4) SSE ì§„í–‰ ìŠ¤íŠ¸ë¦¼
@router.get("/analysis-progress/{job_id}/")
async def stream_progress(job_id: str):
    async def gen():
        while True:
            db = SessionLocal()
            try:
                r = get_script_result(db, job_id)
                if not r:
                    yield "data: {\"error\":\"Job not found\"}\n\n"
                    break
                data = {
                    "job_id":   r.job_id,
                    "status":   r.status,
                    "progress": r.progress,
                    "message":  r.message,
                    "result":   r.result,
                }
                yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
                if r.status in ("completed", "failed"): break
            finally:
                db.close()
            await asyncio.sleep(1)
    return StreamingResponse(gen(), media_type="text/event-stream",
                             headers={"Cache-Control":"no-cache",
                                      "Connection":"keep-alive",
                                      "Access-Control-Allow-Origin":"*"})
