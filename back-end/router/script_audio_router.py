# router/script_audio_router.py
import os, logging, asyncio, json, io, httpx
from uuid import uuid4
from concurrent.futures import ThreadPoolExecutor
from fastapi import (
    APIRouter, Path, UploadFile, File, Request,
    BackgroundTasks, Depends, HTTPException
)
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session, joinedload
from database import get_db, SessionLocal
from models import Script, AnalysisResult, User
from schemas import ScriptUser, ScriptWordUser      # â˜… Pydantic ìŠ¤í‚¤ë§ˆ
from router.auth_router import get_current_user     # ì¸ì¦ í•¨ìˆ˜ import
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from datetime import datetime, timedelta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
scheduler = AsyncIOScheduler()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„ íƒì  ì¸ì¦ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
security = HTTPBearer(auto_error=False)  # auto_error=Falseë¡œ ì„¤ì •

def get_current_user_optional(
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security),
    db: Session = Depends(get_db)
) -> Optional[User]:
    """
    ì„ íƒì  ì¸ì¦: í† í°ì´ ìˆìœ¼ë©´ ì‚¬ìš©ì ë°˜í™˜, ì—†ìœ¼ë©´ None ë°˜í™˜
    """
    if not credentials:
        return None
    
    try:
        from router.auth_router import verify_token
        token = credentials.credentials
        payload = verify_token(token)
        
        user_id: str = payload.get("sub")
        if user_id is None:
            return None
        
        user = db.query(User).filter(User.id == user_id).first()
        return user
    except:
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
S3_BUCKET   = os.getenv("S3_BUCKET_NAME")
TARGET_URL  = os.getenv("SCRIPT_TARGET_SERVER_URL")
WEBHOOK_URL = os.getenv("SCRIPT_WEBHOOK_URL")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìµëª… ì‚¬ìš©ì ê²°ê³¼ ë°°ì¹˜ ì‚­ì œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def cleanup_anonymous_results():
    """
    user_idê°€ NULLì¸ ìµëª… ì‚¬ìš©ìì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°°ì¹˜ë¡œ ì‚­ì œ
    1ë¶„ ì´ìƒ ëœ ë ˆì½”ë“œë“¤ë§Œ ì‚­ì œ
    """
    db = SessionLocal()
    try:
        # 10ì´ˆ ì´ìƒ ëœ ìµëª… ì‚¬ìš©ì ê²°ê³¼ë“¤ ì‚­ì œ (í…ŒìŠ¤íŠ¸ìš©)
        deleted_count = db.query(AnalysisResult).filter(
            AnalysisResult.user_id.is_(None),
            AnalysisResult.created_at < datetime.utcnow() - timedelta(seconds=60)
        ).delete(synchronize_session=False)
        
        db.commit()
        
        if deleted_count > 0:
            logging.info(f"[ë°°ì¹˜ ì‚­ì œ ì™„ë£Œ] ìµëª… ì‚¬ìš©ì ê²°ê³¼ {deleted_count}ê°œ ì‚­ì œë¨")
        else:
            logging.info("[ë°°ì¹˜ ì‚­ì œ] ì‚­ì œí•  ìµëª… ì‚¬ìš©ì ê²°ê³¼ ì—†ìŒ")
            
    except Exception as e:
        logging.error(f"[ë°°ì¹˜ ì‚­ì œ ì‹¤íŒ¨] error={e}")
        db.rollback()
    finally:
        db.close()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_script_result(db: Session, job_id: str, token_id: int , user_id: int = None):

    ar = AnalysisResult(
        job_id=job_id, 
        token_id=token_id,
        user_id=user_id,
        # script_id=script_id,
        status="processing", 
        progress=10, 
        message="ì—…ë¡œë“œ ì‹œì‘"
    )

    db.add(ar); 
    db.commit(); 
    db.refresh(ar); 
    return ar

def update_script_result(db: Session, job_id: str, **kw):
    ar = db.query(AnalysisResult).filter_by(job_id=job_id).first()
    if ar:
        for k, v in kw.items(): setattr(ar, k, v)
        db.commit(); db.refresh(ar)
    return ar

def get_script_result(db: Session, job_id: str):
    return db.query(AnalysisResult).filter_by(job_id=job_id).first()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ScriptUser ë¹Œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_script_user(db: Session, script_id: int) -> ScriptUser:
    script: Script = (
        db.query(Script)
          .options(joinedload(Script.words))
          .filter_by(id=script_id).first()
    )
    if not script:
        raise HTTPException(404, "Script not found")

    words = [
        ScriptWordUser(
            id=w.id,
            start_time=w.start_time,
            end_time=w.end_time,
            word=w.word,
            mfcc=w.mfcc        # DBì— ì €ì¥ë¼ ìˆë˜ MFCC(2-D ë¦¬ìŠ¤íŠ¸)
        ) for w in script.words
    ]
    return ScriptUser(id=script.id, words=words)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¹„ë™ê¸° ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def upload_to_s3_async(s3_client, file_bytes: bytes, filename: str, user_id: Optional[str], token_id: int, script_id: int) -> str:
    def _sync():
        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ, ì—†ìœ¼ë©´ 'mp3' ê¸°ë³¸ ì‚¬ìš©
        file_extension = filename.split('.')[-1] if '.' in filename else 'mp3'
        
        # ë¡œê·¸ì¸ ì‚¬ìš©ìì¸ ê²½ìš° user_id, token_id, script_idë¡œ í‚¤ ìƒì„±
        if user_id:
            key = f"user_audio/{user_id}/{token_id}/{script_id}.{file_extension}"
        # ìµëª… ì‚¬ìš©ìì¸ ê²½ìš° ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ëœë¤ í‚¤ ìƒì„±
        else:
            key = f"audio/{uuid4().hex}_{filename}"
        
        # S3ì— íŒŒì¼ ì—…ë¡œë“œ (ë®ì–´ì“°ê¸°)
        s3_client.upload_fileobj(
            io.BytesIO(file_bytes), 
            S3_BUCKET, 
            key,
            ExtraArgs={'ContentType': 'audio/mpeg'} # ContentType ëª…ì‹œ
        )
        return key

    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as ex:
        return await loop.run_in_executor(ex, _sync)

async def send_analysis_async(s3_url: str, script_obj: ScriptUser,
                              webhook_url: str, job_id: str):
    """ë¶„ì„ ì„œë²„ë¡œ JSON(payload) ì „ì†¡"""
    payload = {
        "s3_audio_url": s3_url,
        "webhook_url":  webhook_url,
        "script":       script_obj.dict()   # Pydantic â†’ dict
    }
    # JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”
    form_data = {
        "request_data": json.dumps(payload, ensure_ascii=False)
    }

    try:
        async with httpx.AsyncClient(timeout=30) as client:
            resp = await client.post(
                url=TARGET_URL,
                data=form_data,  # â˜… json=X, data=O
                headers={"Content-Type": "application/x-www-form-urlencoded"}
            )
            resp.raise_for_status()
            logging.info(f"[ë¶„ì„ ìš”ì²­ ì„±ê³µ] job_id={job_id}")
    except httpx.HTTPError as e:
        logging.error(f"[ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨] job_id={job_id} - {e}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Router â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/scripts", tags=["scripts"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def start_cleanup_scheduler():
    """ìµëª… ì‚¬ìš©ì ê²°ê³¼ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    if not scheduler.running:
        # 1ë¶„ë§ˆë‹¤ ë°°ì¹˜ ì‚­ì œ ì‹¤í–‰
        scheduler.add_job(
            cleanup_anonymous_results,
            'interval',
            minutes=1,
            id='cleanup_anonymous_results',
            replace_existing=True
        )
        scheduler.start()
        logging.info("[ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘] ìµëª… ì‚¬ìš©ì ê²°ê³¼ 1ë¶„ë§ˆë‹¤ ìë™ ì‚­ì œ ì‹œì‘")

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
start_cleanup_scheduler()

# 1) ì—…ë¡œë“œ + ë¶„ì„ ìš”ì²­
@router.post("/{script_id}/upload-audio")
async def upload_script_audio(
    request: Request,
    script_id: int = Path(...),
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional),  # ğŸ”“ ì„ íƒì  ì¸ì¦
):
    script = db.query(Script).filter_by(id=script_id).first()

    if not script:
        raise HTTPException(404, "Script not found")

    # ScriptUser ê°ì²´ë¡œ ì§ë ¬í™”
    script_obj = build_script_user(db, script_id)

    # S3Â·ë¶„ì„ ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸
    s3_client   = request.app.state.s3_client
    job_id      = uuid4().hex
    file_bytes  = await file.read()

    # ë¡œê·¸ì¸í•œ ì‚¬ìš©ìê°€ ìˆìœ¼ë©´ user_id ì €ì¥, ì—†ìœ¼ë©´ None
    user_id = current_user.id if current_user else None
    create_script_result(db, job_id, token_id=script.token_id, user_id=user_id)

    async def bg_work(client_, user_id_, token_id_, script_id_):
        bg_db = SessionLocal()
        try:
            update_script_result(bg_db, job_id, progress=40, message="S3 ì—…ë¡œë“œ")
            key   = await upload_to_s3_async(client_, file_bytes, file.filename, user_id_, token_id_, script_id_)
            s3url = f"s3://{S3_BUCKET}/{key}"

            update_script_result(bg_db, job_id, progress=70, message="ë¶„ì„ ì„œë²„ í˜¸ì¶œ")
            cb    = f"{WEBHOOK_URL}?job_id={job_id}"
            await send_analysis_async(s3url, script_obj, cb, job_id)

            # ì›¹í›… ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
            update_script_result(bg_db, job_id, progress=90, message="ë¶„ì„ ì¤‘â€¦")
                
        except Exception as e:
            logging.error(e)
            update_script_result(bg_db, job_id, status="failed",
                                 message=str(e), progress=0)
        finally:
            bg_db.close()

    background_tasks.add_task(bg_work, s3_client, user_id, script.token_id, script_id)
    return {"message": "ì—…ë¡œë“œ ì™„ë£Œ, ë¶„ì„ ì‹œì‘",
            "job_id": job_id, "status": "processing"}

# 2) ë¶„ì„ ì„œë²„ ì›¹í›…
@router.post("/webhook/analysis-complete")
async def analysis_webhook(request: Request, db: Session = Depends(get_db)):
    # ì›¹í›… í˜¸ì¶œ ë¡œê¹… ì¶”ê°€
    logging.info("=" * 50)
    logging.info("[ğŸ”” ì›¹í›… í˜¸ì¶œë¨] Scripts ë¶„ì„ ê²°ê³¼ ì›¹í›… ìˆ˜ì‹ ")
    logging.info(f"[ì›¹í›… ìš”ì²­ IP] {request.client.host if request.client else 'Unknown'}")
    logging.info(f"[ì›¹í›… í—¤ë”] {dict(request.headers)}")
    
    job_id = request.query_params.get("job_id")
    logging.info(f"[ì›¹í›… íŒŒë¼ë¯¸í„°] job_id={job_id}")
    
    if not job_id:
        logging.warning("[â—ê²½ê³ ] Scripts ì›¹í›…ì— job_id ì—†ìŒ")
        raise HTTPException(400, "job_id missing")
        
    payload = await request.json()
    logging.info(f"[ì›¹í›… ë°ì´í„°] ë°›ì€ ê²°ê³¼ í¬ê¸°: {len(str(payload))} ë¬¸ì")
    logging.info(f"[ì›¹í›… ë°ì´í„°] ê²°ê³¼ í‚¤ë“¤: {list(payload.keys()) if isinstance(payload, dict) else 'Not dict'}")
    
    # ë¶„ì„ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
    analysis_result = update_script_result(db, job_id, status="completed",
                         progress=100, result=payload, message="ë¶„ì„ ì™„ë£Œ")
    
    logging.info(f"[âœ… ì›¹í›… ì²˜ë¦¬ ì™„ë£Œ] job_id={job_id}")
    logging.info("=" * 50)
    return {"received": True, "job_id": job_id}

# 3) ê²°ê³¼ ì¡°íšŒ
@router.get("/analysis-result/{job_id}")
def get_result(job_id: str, db: Session = Depends(get_db)):
    r = get_script_result(db, job_id)
    if not r:
        raise HTTPException(404, "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return {
        "job_id":    r.job_id,
        "token_id":  r.token_id,   # script_id í•„ë“œ ì œê±°
        # "script_id": r.script_id,
        "status":    r.status,
        "progress":  r.progress,
        "result":    r.result,
        "message":   r.message,
        "created_at": r.created_at,
    }

# ğŸ§¹ ë°°ì¹˜ ì‚­ì œ API (ìˆ˜ë™ ì‹¤í–‰ìš©)
@router.post("/cleanup/anonymous-results")
async def manual_cleanup_anonymous_results():
    """ìˆ˜ë™ìœ¼ë¡œ ìµëª… ì‚¬ìš©ì ê²°ê³¼ ë°°ì¹˜ ì‚­ì œ ì‹¤í–‰"""
    await cleanup_anonymous_results()
    return {"message": "ìµëª… ì‚¬ìš©ì ê²°ê³¼ ì •ë¦¬ ì‘ì—… ì™„ë£Œ"}

# 4) SSE ì§„í–‰ ìŠ¤íŠ¸ë¦¼
# @router.get("/analysis-progress/{job_id}")
# async def stream_progress(job_id: str):
#     async def gen():
#         while True:
#             db = SessionLocal()
#             try:
#                 r = get_script_result(db, job_id)
#                 if not r:
#                     yield "data: {\"error\":\"Job not found\"}\n\n"
#                     break
#                 data = {
#                     "job_id":   r.job_id,
#                     "status":   r.status,
#                     "progress": r.progress,
#                     "message":  r.message,
#                     "result":   r.result,
#                 }
#                 yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
#                 if r.status in ("completed", "failed"): break
#             finally:
#                 db.close()
#             await asyncio.sleep(1)
#     return StreamingResponse(gen(), media_type="text/event-stream",
#                              headers={"Cache-Control":"no-cache",
#                                       "Connection":"keep-alive",
#                                       "Access-Control-Allow-Origin":"*"})
@router.get("/analysis-progress/{job_id}")
async def stream_progress(job_id: str, request: Request):
    async def gen():
        max_runtime = 30
        start_time = datetime.utcnow()

        while True:
            if await request.is_disconnected():
                print(f"[SSE] ì—°ê²° ì¢…ë£Œ ê°ì§€ë¨: job_id={job_id}")
                break
            db = SessionLocal()
            try:
                r = get_script_result(db, job_id)
                if not r:
                    yield "data: {\"error\":\"Job not found\"}\n\n"
                    break
                data = {
                    "job_id":   r.job_id,
                    "status":   r.status,
                    "progress": r.progress,
                    "message":  r.message,
                    "result":   r.result,
                }
                yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
                if r.status in ("completed", "failed"):
                    break
                if (datetime.utcnow() - start_time).total_seconds() > max_runtime:
                    print(f"[SSE] SSE íƒ€ì„ì•„ì›ƒ ì¢…ë£Œ: job_id={job_id}")
                    break
            finally:
                db.close()
            await asyncio.sleep(1)
    return StreamingResponse(gen(), media_type="text/event-stream",
                             headers={"Cache-Control":"no-cache",
                                      "Connection":"keep-alive",
                                      "Access-Control-Allow-Origin":"*"})
