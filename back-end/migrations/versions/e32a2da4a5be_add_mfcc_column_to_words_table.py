"""add mfcc column to words table

Revision ID: e32a2da4a5be
Revises: 610f93aeb2e8
Create Date: 2025-07-07 14:41:50.433440

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'e32a2da4a5be'
down_revision: Union[str, Sequence[str], None] = '610f93aeb2e8'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(op.f('actor_aliases_actor_id_name_key'), 'actor_aliases', type_='unique')
    op.create_unique_constraint('uq_actor_alias', 'actor_aliases', ['actor_id', 'name'])
    op.drop_constraint(op.f('actors_name_key'), 'actors', type_='unique')
    op.drop_index(op.f('ix_actors_name'), table_name='actors')
    op.create_index(op.f('ix_actors_name'), 'actors', ['name'], unique=True)
    op.add_column('analysis_results', sa.Column('job_id', sa.String(), nullable=True))
    op.add_column('analysis_results', sa.Column('status', sa.String(), nullable=False))
    op.add_column('analysis_results', sa.Column('progress', sa.Integer(), nullable=False))
    op.add_column('analysis_results', sa.Column('result', sa.JSON(), nullable=True))
    op.add_column('analysis_results', sa.Column('message', sa.String(), nullable=True))
    op.drop_index(op.f('ix_analysis_results_token_id'), table_name='analysis_results')
    op.create_index(op.f('ix_analysis_results_job_id'), 'analysis_results', ['job_id'], unique=True)
    op.drop_column('analysis_results', 'analysis_data')
    op.alter_column('bookmarks', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_constraint(op.f('bookmarks_user_id_token_id_key'), 'bookmarks', type_='unique')
    op.drop_index(op.f('ix_bookmarks_id'), table_name='bookmarks')
    op.drop_column('bookmarks', 'id')
    op.create_unique_constraint('uq_token_actor', 'token_actors', ['token_id', 'actor_id'])
    op.drop_index(op.f('ix_tokens_view_count'), table_name='tokens')
    op.drop_column('tokens', 'view_count')
    op.alter_column('users', 'email',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_constraint(op.f('users_google_id_key'), 'users', type_='unique')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.drop_index(op.f('ix_users_google_id'), table_name='users')
    op.create_index(op.f('ix_users_google_id'), 'users', ['google_id'], unique=True)
    op.add_column('words', sa.Column('probability', sa.Float(), nullable=True))
    op.add_column('words', sa.Column('mfcc', sa.JSON(), nullable=True))
    op.alter_column('words', 'word',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('words', 'start_time',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.alter_column('words', 'end_time',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('words', 'end_time',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('words', 'start_time',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('words', 'word',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_column('words', 'mfcc')
    op.drop_column('words', 'probability')
    op.drop_index(op.f('ix_users_google_id'), table_name='users')
    op.create_index(op.f('ix_users_google_id'), 'users', ['google_id'], unique=False)
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=False)
    op.create_unique_constraint(op.f('users_google_id_key'), 'users', ['google_id'], postgresql_nulls_not_distinct=False)
    op.alter_column('users', 'email',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.add_column('tokens', sa.Column('view_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.create_index(op.f('ix_tokens_view_count'), 'tokens', ['view_count'], unique=False)
    op.drop_constraint('uq_token_actor', 'token_actors', type_='unique')
    op.add_column('bookmarks', sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False))
    op.create_index(op.f('ix_bookmarks_id'), 'bookmarks', ['id'], unique=False)
    op.create_unique_constraint(op.f('bookmarks_user_id_token_id_key'), 'bookmarks', ['user_id', 'token_id'], postgresql_nulls_not_distinct=False)
    op.alter_column('bookmarks', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.add_column('analysis_results', sa.Column('analysis_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_analysis_results_job_id'), table_name='analysis_results')
    op.create_index(op.f('ix_analysis_results_token_id'), 'analysis_results', ['token_id'], unique=False)
    op.drop_column('analysis_results', 'message')
    op.drop_column('analysis_results', 'result')
    op.drop_column('analysis_results', 'progress')
    op.drop_column('analysis_results', 'status')
    op.drop_column('analysis_results', 'job_id')
    op.drop_index(op.f('ix_actors_name'), table_name='actors')
    op.create_index(op.f('ix_actors_name'), 'actors', ['name'], unique=False)
    op.create_unique_constraint(op.f('actors_name_key'), 'actors', ['name'], postgresql_nulls_not_distinct=False)
    op.drop_constraint('uq_actor_alias', 'actor_aliases', type_='unique')
    op.create_unique_constraint(op.f('actor_aliases_actor_id_name_key'), 'actor_aliases', ['actor_id', 'name'], postgresql_nulls_not_distinct=False)
    # ### end Alembic commands ###
